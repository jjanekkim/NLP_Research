{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevance\n",
    "\n",
    "**Relevance** refers to the importance or pertinence of certain pieces of information within a text to a specific task or query.\n",
    "\n",
    "- `Information Retrieval (IR)`: In tasks like question answering and fact verification, relevance determines which documents or pieces of information are most pertinent to the query. An IR system retrieves relevant documents, which an NLP system then processes to extract the needed information.\n",
    "- `Text Classification`: When categorizing text documents, relevance helps identify which words or phrases are most significant for determining the category. Techniques like Layer-wise Relevance Propagation (LRP) can trace classification decisions back to individual words, highlighting their importance.\n",
    "- `Sentiment Analysis`: Relevance is used to focus on words or phrases that carry sentiment, such as positive or negative emotions, to accurately gauge the overall sentiment of a text.\n",
    "- `Named Entity Recognition (NER)`: In NER, relevance helps in identifying and classifying entities (like names, dates, and locations) within a text. The relevance of a word or phrase to a particular entity type is crucial for accurate recognition.\n",
    "- `Contextual Understanding`: Relevance is essential for understanding the context in which words are used. This helps in tasks like machine translation, where the meaning of a word can change based on its context.\n",
    "\n",
    "**Models and Techniques**\n",
    "\n",
    "- `TF-IDF` (Term Frequency-Inverse Document Frequency): This is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents. It helps in identifying the most relevant terms in a document.\n",
    "- `BM25`: An extension of the TF-IDF model, BM25 is a ranking function used by search engines to estimate the relevance of documents to a given search query.\n",
    "- `Word2Vec` and `GloVe`: These are word embedding models that capture semantic relationships between words. They can be used to measure the relevance of words in a context by comparing their vector representations.\n",
    "- `BERT` (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based model that understands the context of a word in a sentence by looking at the words before and after it. It is highly effective in tasks requiring contextual relevance, such as question answering and text classification.\n",
    "\n",
    "**Why is it important?**\n",
    "\n",
    "1. Improve Accuracy\n",
    "2. Efficiency / Resource Optimization\n",
    "3. Contextual Understanding\n",
    "4. User Satisfaction\n",
    "5. Enhanced Decision-Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chat_ID</th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_science_trend</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>What is the latest trend in data science?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_science_trend</td>\n",
       "      <td>1</td>\n",
       "      <td>copilot</td>\n",
       "      <td>Data science is evolving rapidly, and several ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_science_trend</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>Can you tell me more about generative AI?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_science_trend</td>\n",
       "      <td>3</td>\n",
       "      <td>copilot</td>\n",
       "      <td>Generative AI is a fascinating and rapidly evo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_science_trend</td>\n",
       "      <td>4</td>\n",
       "      <td>user</td>\n",
       "      <td>can you explain more about how the generative ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Chat_ID  Message_ID   Sender   \n",
       "0  data_science_trend           0     user  \\\n",
       "1  data_science_trend           1  copilot   \n",
       "2  data_science_trend           2     user   \n",
       "3  data_science_trend           3  copilot   \n",
       "4  data_science_trend           4     user   \n",
       "\n",
       "                                             Message  \n",
       "0          What is the latest trend in data science?  \n",
       "1  Data science is evolving rapidly, and several ...  \n",
       "2          Can you tell me more about generative AI?  \n",
       "3  Generative AI is a fascinating and rapidly evo...  \n",
       "4  can you explain more about how the generative ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\nene0\\Desktop\\Projects\\greenflash\\chat_data.csv\", encoding_errors='ignore')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data_science_trend', 'food_history_companies', 'gaming',\n",
       "       'greek_myth', 'job_market', 'jokes', 'music_kpop', 'pets',\n",
       "       'philoshophy', 'rich_poor_countries',\n",
       "       'tech_product_recommendation', 'travel', 'largest_adj_product',\n",
       "       'jarritos_flavors', 'reason_for_sleepiness'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Chat_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chat_ID</th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>greek_myth</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>can you give me happy short story to uplift my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>greek_myth</td>\n",
       "      <td>1</td>\n",
       "      <td>copilot</td>\n",
       "      <td>Absolutely! Here's a short, uplifting story fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>greek_myth</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>hmmmm very normal story nothing touching... ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>greek_myth</td>\n",
       "      <td>3</td>\n",
       "      <td>copilot</td>\n",
       "      <td>Sure! Here are some fun and interesting facts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>greek_myth</td>\n",
       "      <td>4</td>\n",
       "      <td>user</td>\n",
       "      <td>I heard there is a greek myth behind the sunfl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Chat_ID  Message_ID   Sender   \n",
       "96   greek_myth           0     user  \\\n",
       "97   greek_myth           1  copilot   \n",
       "98   greek_myth           2     user   \n",
       "99   greek_myth           3  copilot   \n",
       "100  greek_myth           4     user   \n",
       "\n",
       "                                               Message  \n",
       "96   can you give me happy short story to uplift my...  \n",
       "97   Absolutely! Here's a short, uplifting story fo...  \n",
       "98   hmmmm very normal story nothing touching... ca...  \n",
       "99   Sure! Here are some fun and interesting facts ...  \n",
       "100  I heard there is a greek myth behind the sunfl...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myth = df[df['Chat_ID']=='greek_myth']\n",
    "\n",
    "myth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can you tell me what happen to odysseus after he returned to his home after the war?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myth.iloc[8]['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! After enduring numerous adventures and challenges on his journey home from the Trojan War, Odysseus finally returned to his homeland of Ithaca. Here's a summary of what happened next:\\n- Disguised Return: Upon arriving in Ithaca, Odysseus disguised himself as a beggar with the help of the goddess Athena. This allowed him to assess the situation at home without being recognized.\\n- Reunion with Telemachus: Odysseus first revealed his true identity to his son, Telemachus. Together, they devised a plan to deal with the suitors who had overrun their home.\\n- Penelope's Loyalty: Penelope, Odysseus's wife, had remained faithful to him despite being pressured by numerous suitors. She devised clever ways to delay remarrying, such as weaving and then secretly unraveling a shroud.\\n- The Contest of the Bow: Penelope announced a contest to the suitors: whoever could string Odysseus's great bow and shoot an arrow through twelve axe heads would win her hand. None of the suitors could accomplish the task, but Odysseus, still in disguise, succeeded effortlessly.\\n- Reclaiming His Throne: After revealing his identity, Odysseus, with the help of Telemachus and a few loyal servants, defeated the suitors in a fierce battle, reclaiming his home and throne.\\n- Reunion with Penelope: Finally, Odysseus and Penelope were joyfully reunited. Penelope tested Odysseus to ensure it was truly him by asking about their bed, which he had built himself and was immovable.\\n- Peace Restored: Athena intervened to ensure peace in Ithaca, preventing further bloodshed and helping Odysseus reestablish his rule.\\nOdysseus's return was marked by cleverness, bravery, and the enduring love and loyalty of his family. It's a fitting conclusion to his long and arduous journey.\\nIs there another part of Greek mythology or a different story you're curious about?\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myth.iloc[9]['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_8 = word_tokenize(myth.iloc[8]['Message'])\n",
    "message_9 = word_tokenize(myth.iloc[9]['Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " \"'s\",\n",
       " \"'t\",\n",
       " \"'ll\",\n",
       " \"'d\",\n",
       " \"'re\"]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Add more stopwords myself.\n",
    "stop_words.extend([\"'s\", \"'t\", \"'ll\",\"'d\",\"'re\"])\n",
    "\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\"'\", ',', '.', '?', '!', '/', '-', '@', '#', '$', '%', '^', '&', '*', '(', ')', '[', ']', '{', '}', '_', '+', '=', ';', ':', '~', '`', '<', '>', '|']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(list_words):\n",
    "    new_text = []\n",
    "    for word in list_words:\n",
    "        if word.lower() not in stop_words and word.lower() not in symbols:\n",
    "            new_text.append(word)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cleaned = remove_stop_words(message_8)\n",
    "response_cleaned = remove_stop_words(message_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 166\n"
     ]
    }
   ],
   "source": [
    "print(len(message_9), len(response_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell happen odysseus returned home war'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_cleaned = ' '.join(question_cleaned)\n",
    "question_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly enduring numerous adventures challenges journey home Trojan War Odysseus finally returned homeland Ithaca summary happened next Disguised Return Upon arriving Ithaca Odysseus disguised beggar help goddess Athena allowed assess situation home without recognized Reunion Telemachus Odysseus first revealed true identity son Telemachus Together devised plan deal suitors overrun home Penelope Loyalty Penelope Odysseus wife remained faithful despite pressured numerous suitors devised clever ways delay remarrying weaving secretly unraveling shroud Contest Bow Penelope announced contest suitors whoever could string Odysseus great bow shoot arrow twelve axe heads would win hand None suitors could accomplish task Odysseus still disguise succeeded effortlessly Reclaiming Throne revealing identity Odysseus help Telemachus loyal servants defeated suitors fierce battle reclaiming home throne Reunion Penelope Finally Odysseus Penelope joyfully reunited Penelope tested Odysseus ensure truly asking bed built immovable Peace Restored Athena intervened ensure peace Ithaca preventing bloodshed helping Odysseus reestablish rule Odysseus return marked cleverness bravery enduring love loyalty family fitting conclusion long arduous journey another part Greek mythology different story curious'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_cleaned = ' '.join(response_cleaned)\n",
    "response_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score: 0.301656654885515\n"
     ]
    }
   ],
   "source": [
    "prompt = myth.iloc[4]['Message']\n",
    "response = myth.iloc[5]['Message']\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([prompt, response])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "print(\"Relevance Score:\", similarity[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score: 0.24003883165382472\n"
     ]
    }
   ],
   "source": [
    "prompt = question_cleaned\n",
    "response = response_cleaned\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([prompt, response])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "print(\"Relevance Score:\", similarity[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
