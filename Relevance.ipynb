{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevance\n",
    "\n",
    "**Relevance** refers to the importance or pertinence of certain pieces of information within a text to a specific task or query.\n",
    "\n",
    "- `Information Retrieval (IR)`: In tasks like question answering and fact verification, relevance determines which documents or pieces of information are most pertinent to the query. An IR system retrieves relevant documents, which an NLP system then processes to extract the needed information.\n",
    "- `Text Classification`: When categorizing text documents, relevance helps identify which words or phrases are most significant for determining the category. Techniques like Layer-wise Relevance Propagation (LRP) can trace classification decisions back to individual words, highlighting their importance.\n",
    "- `Sentiment Analysis`: Relevance is used to focus on words or phrases that carry sentiment, such as positive or negative emotions, to accurately gauge the overall sentiment of a text.\n",
    "- `Named Entity Recognition (NER)`: In NER, relevance helps in identifying and classifying entities (like names, dates, and locations) within a text. The relevance of a word or phrase to a particular entity type is crucial for accurate recognition.\n",
    "- `Contextual Understanding`: Relevance is essential for understanding the context in which words are used. This helps in tasks like machine translation, where the meaning of a word can change based on its context.\n",
    "\n",
    "**Models and Techniques**\n",
    "\n",
    "- `TF-IDF` (Term Frequency-Inverse Document Frequency): This is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents. It helps in identifying the most relevant terms in a document.\n",
    "- `BM25`: An extension of the TF-IDF model, BM25 is a ranking function used by search engines to estimate the relevance of documents to a given search query.\n",
    "- `Word2Vec` and `GloVe`: These are word embedding models that capture semantic relationships between words. They can be used to measure the relevance of words in a context by comparing their vector representations.\n",
    "- `BERT` (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based model that understands the context of a word in a sentence by looking at the words before and after it. It is highly effective in tasks requiring contextual relevance, such as question answering and text classification.\n",
    "\n",
    "**Why is it important?**\n",
    "\n",
    "1. Improve Accuracy\n",
    "2. Efficiency / Resource Optimization\n",
    "3. Contextual Understanding\n",
    "4. User Satisfaction\n",
    "5. Enhanced Decision-Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score: 0.45026814465562653\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about the weather in California.\"\n",
    "response = \"The weather in California is sunny.\"\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([prompt, response])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "print(\"Relevance Score:\", similarity[0][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
